from project_types import Scenario
from typing import List, Optional, Literal
from datasets import load_dataset, Dataset
import random

HF_REPO_ID = "deathbyknowledge/V3-shell-format"

eval = [
    {"prompt": [{"role": "system", "content": "The 'webapp' service stores user uploads in '/var/www/uploads'. Find all files with the '.tmp' extension and delete them, as they are no longer needed."}], "completion": [{"role": "assistant", "content": "# To find and delete all files with the '.tmp' extension in '/var/www/uploads', I will use the 'find' command to locate these files and then delete them using the '-delete' option."}, {"role": "user", "content": ""}, {"role": "assistant", "content": "find /var/www/uploads -type f -name \"*.tmp\" -delete"}, {"role": "user", "content": ""}, {"role": "assistant", "content": "exit 0"}], "id": "she_syn_t3370", "setup_commands": ["mkdir -p /var/www/uploads", "touch /var/www/uploads/file1.tmp", "touch /var/www/uploads/file2.txt"], "success_condition": "[ ! -f /var/www/uploads/file1.tmp ] && [ -f /var/www/uploads/file2.txt ]"},
    {"prompt": [{"role": "system", "content": "A developer accidentally left temporary files in the '/home/dev/projects/nebula-core' directory. These files have names ending with '.tmp'. Remove all such files to clean up the project directory."}], "completion": [{"role": "assistant", "content": "# To remove all temporary files with the '.tmp' extension in the '/home/dev/projects/nebula-core' directory, I will use the 'find' command to locate these files and then delete them using the '-delete' option."}, {"role": "user", "content": ""}, {"role": "assistant", "content": "find /home/dev/projects/nebula-core -type f -name \"*.tmp\" -delete"}, {"role": "user", "content": ""}, {"role": "assistant", "content": "exit 0"}], "id": "she_syn_t662", "setup_commands": ["mkdir -p /home/dev/projects/nebula-core", "touch /home/dev/projects/nebula-core/config.tmp", "touch /home/dev/projects/nebula-core/data.tmp", "touch /home/dev/projects/nebula-core/README.md"], "success_condition": "! find /home/dev/projects/nebula-core -name '*.tmp' | grep -q '.'"},
    {"prompt": [{"role": "system", "content": "The 'user-uploads' directory contains files uploaded by users. Find all files with the '.tmp' extension in '/var/www/user-uploads' and delete them to free up space."}], "completion": [{"role": "assistant", "content": "# To find and delete all files with the '.tmp' extension in the '/var/www/user-uploads' directory, I will use the 'find' command to locate these files and then delete them using the '-delete' option."}, {"role": "user", "content": ""}, {"role": "assistant", "content": "find /var/www/user-uploads -type f -name '*.tmp' -delete"}, {"role": "user", "content": ""}, {"role": "assistant", "content": "exit 0"}], "id": "she_syn_t7496", "setup_commands": ["mkdir -p /var/www/user-uploads", "touch /var/www/user-uploads/file1.tmp", "touch /var/www/user-uploads/file2.tmp", "touch /var/www/user-uploads/file3.txt"], "success_condition": "! find /var/www/user-uploads -name '*.tmp' | grep -q '.'"},
    {"prompt": [{"role": "system", "content": "A developer accidentally committed sensitive data in a file named 'credentials.env' within the 'mercury-api' project directory. Locate and remove this file from the '/opt/mercury-api/config' folder."}], "completion": [{"role": "assistant", "content": "# To locate and remove the sensitive file 'credentials.env' in the '/opt/mercury-api/config' directory, I will first verify the existence of the file and then proceed to delete it."}, {"role": "user", "content": ""}, {"role": "assistant", "content": "ls /opt/mercury-api/config/credentials.env"}, {"role": "user", "content": "/opt/mercury-api/config/credentials.env\n"}, {"role": "assistant", "content": "# The file 'credentials.env' exists in the specified directory. The next step is to safely remove this file to ensure the sensitive data is deleted."}, {"role": "user", "content": ""}, {"role": "assistant", "content": "rm /opt/mercury-api/config/credentials.env"}, {"role": "user", "content": ""}, {"role": "assistant", "content": "exit 0"}], "id": "she_syn_t6407", "setup_commands": ["mkdir -p /opt/mercury-api/config", "echo 'API_KEY=12345' > /opt/mercury-api/config/credentials.env"], "success_condition": "[ ! -f /opt/mercury-api/config/credentials.env ]"},
    {"prompt": [{"role": "system", "content": "A data processing job in '/data/jobs' creates intermediate files with the prefix 'temp_'. Count how many such files exist and save the count to '/tmp/temp_file_count.txt'."}], "completion": [{"role": "assistant", "content": "# To complete the task, I need to count the number of files in '/data/jobs' that have the prefix 'temp_'. Then, I will save this count to '/tmp/temp_file_count.txt'. The first step is to list all files with the prefix 'temp_' in the specified directory and count them."}, {"role": "user", "content": ""}, {"role": "assistant", "content": "find /data/jobs -name 'temp_*' -type f | wc -l > /tmp/temp_file_count.txt"}, {"role": "user", "content": ""}, {"role": "assistant", "content": "exit 0"}], "id": "she_syn_t6058", "setup_commands": ["mkdir -p /data/jobs", "touch /data/jobs/temp_001.dat", "touch /data/jobs/temp_002.dat", "touch /data/jobs/output_001.dat"], "success_condition": "grep -q '2' /tmp/temp_file_count.txt"},
    {"prompt": [{"role": "system", "content": "The 'api-gateway' service stores configuration files in '/etc/api-gateway'. List all files with the '.conf' extension and sort them alphabetically by filename, saving the result to '/tmp/sorted_configs.txt'."}], "completion": [{"role": "assistant", "content": "# To list all files with the '.conf' extension in '/etc/api-gateway', sort them alphabetically by filename, and save the result to '/tmp/sorted_configs.txt', I will use the 'find' command to locate the files, 'sort' to alphabetize them, and redirect the output to the specified file."}, {"role": "user", "content": ""}, {"role": "assistant", "content": "find /etc/api-gateway -type f -name '*.conf' | sort > /tmp/sorted_configs.txt"}, {"role": "user", "content": ""}, {"role": "assistant", "content": "exit 0"}], "id": "she_syn_t2137", "setup_commands": ["mkdir -p /etc/api-gateway", "touch /etc/api-gateway/zebra.conf", "touch /etc/api-gateway/alpha.conf", "touch /etc/api-gateway/beta.conf"], "success_condition": "head -n 1 /tmp/sorted_configs.txt | grep -q 'alpha.conf' && tail -n 1 /tmp/sorted_configs.txt | grep -q 'zebra.conf'"},
    {"prompt": [{"role": "system", "content": "A configuration file at '/etc/network/interfaces' has duplicate lines. Remove all duplicate lines from the file while preserving the original order of the remaining lines."}], "completion": [{"role": "assistant", "content": "# To remove duplicate lines from the file while preserving the original order, we can use a combination of shell commands. The 'awk' command is suitable for this task as it can process the file line by line and output only the first occurrence of each line."}, {"role": "user", "content": ""}, {"role": "assistant", "content": "awk '!seen[$0]++' /etc/network/interfaces > /tmp/interfaces.tmp && sudo mv /tmp/interfaces.tmp /etc/network/interfaces"}, {"role": "user", "content": "bash: sudo: command not found\n"}, {"role": "assistant", "content": "# The previous command failed because 'sudo' is not available. Since we need root privileges to modify the '/etc/network/interfaces' file, we can either switch to the root user or use 'su' if available. Alternatively, we can use 'tee' with redirection to write the file as root."}, {"role": "user", "content": ""}, {"role": "assistant", "content": "awk '!seen[$0]++' /etc/network/interfaces | tee /etc/network/interfaces > /dev/null"}, {"role": "user", "content": ""}, {"role": "assistant", "content": "exit 0"}], "id": "she_syn_t11050", "setup_commands": ["mkdir -p /etc/network", "echo 'auto eth0\niface eth0 inet dhcp\nauto eth0\niface eth0 inet dhcp\n' > /etc/network/interfaces"], "success_condition": "uniq -d /etc/network/interfaces | wc -l | grep -q '0' && wc -l /etc/network/interfaces | grep -q '2'"},
    {"prompt": [{"role": "system", "content": "A script in '/opt/scripts' generates output files with random names. Identify and delete all files that are empty, logging their names to '/tmp/empty_files_deleted.log'."}], "completion": [{"role": "assistant", "content": "# To identify and delete empty files in '/opt/scripts' and log their names to '/tmp/empty_files_deleted.log', I will first list all files in the directory, check if they are empty, and then delete them while logging their names."}, {"role": "user", "content": ""}, {"role": "assistant", "content": "find /opt/scripts -type f -empty -exec echo {} \\; > /tmp/empty_files_deleted.log && find /opt/scripts -type f -empty -delete"}, {"role": "user", "content": ""}, {"role": "assistant", "content": "exit 0"}], "id": "she_syn_t1578", "setup_commands": ["mkdir -p /opt/scripts", "touch /opt/scripts/output_123.tmp", "touch /opt/scripts/output_456.tmp", "echo 'data' > /opt/scripts/output_789.tmp"], "success_condition": "! [ -f /opt/scripts/output_123.tmp ] && ! [ -f /opt/scripts/output_456.tmp ] && [ -f /opt/scripts/output_789.tmp ] && grep -q 'output_123.tmp' /tmp/empty_files_deleted.log"},
    {"prompt": [{"role": "system", "content": "The 'hermes-messaging' service stores message queues in '/opt/hermes/queues'. Identify the queue file with the most recent modification time and copy it to '/tmp/latest_queue'."}], "completion": [{"role": "assistant", "content": "# To identify the queue file with the most recent modification time in '/opt/hermes/queues', I will use the 'ls' command with the '-t' flag to sort files by modification time and then select the first one. After identifying the file, I will copy it to '/tmp/latest_queue'."}, {"role": "user", "content": ""}, {"role": "assistant", "content": "ls -t /opt/hermes/queues | head -n 1"}, {"role": "user", "content": "queue_2024-05-19.dat\n"}, {"role": "assistant", "content": "# Now that the most recently modified queue file has been identified as 'queue_2024-05-19.dat', the next step is to copy this file from '/opt/hermes/queues' to '/tmp/latest_queue'."}, {"role": "user", "content": ""}, {"role": "assistant", "content": "cp /opt/hermes/queues/queue_2024-05-19.dat /tmp/latest_queue"}, {"role": "user", "content": ""}, {"role": "assistant", "content": "exit 0"}], "id": "she_syn_t10250", "setup_commands": ["mkdir -p /opt/hermes/queues", "touch -d '2 days ago' /opt/hermes/queues/queue_2024-05-18.dat", "touch -d '1 day ago' /opt/hermes/queues/queue_2024-05-19.dat", "echo 'data' > /opt/hermes/queues/queue_2024-05-19.dat"], "success_condition": "[ -f /tmp/latest_queue ] && [ \"$(ls -t /opt/hermes/queues | head -n 1)\" = \"$(basename /tmp/latest_queue)\" ]"},
    {"prompt": [{"role": "system", "content": "The 'phoenix-api' service logs requests in '/var/log/phoenix/access.log'. Extract the top 5 most frequent IP addresses from the log and save them to '/tmp/top_ips.txt'."}], "completion": [{"role": "assistant", "content": "# To extract the top 5 most frequent IP addresses from the log file, we need to parse the log file, count the occurrences of each IP address, sort them in descending order, and then save the top 5 to the specified file. The command will use a combination of `awk`, `sort`, `uniq`, and `head` utilities."}, {"role": "user", "content": ""}, {"role": "assistant", "content": "awk '{print $1}' /var/log/phoenix/access.log | sort | uniq -c | sort -nr | head -5 > /tmp/top_ips.txt"}, {"role": "user", "content": ""}, {"role": "assistant", "content": "exit 0"}], "id": "she_syn_t12599", "setup_commands": ["mkdir -p /var/log/phoenix", "echo '192.168.1.1 - - [17/May/2024:10:00:00 +0000] \"GET /api HTTP/1.1\" 200 1234' >> /var/log/phoenix/access.log", "echo '192.168.1.1 - - [17/May/2024:10:01:00 +0000] \"GET /api HTTP/1.1\" 200 1234' >> /var/log/phoenix/access.log", "echo '192.168.1.2 - - [17/May/2024:10:02:00 +0000] \"GET /api HTTP/1.1\" 200 1234' >> /var/log/phoenix/access.log", "echo '192.168.1.3 - - [17/May/2024:10:03:00 +0000] \"GET /api HTTP/1.1\" 200 1234' >> /var/log/phoenix/access.log", "echo '192.168.1.4 - - [17/May/2024:10:04:00 +0000] \"GET /api HTTP/1.1\" 200 1234' >> /var/log/phoenix/access.log", "echo '192.168.1.5 - - [17/May/2024:10:05:00 +0000] \"GET /api HTTP/1.1\" 200 1234' >> /var/log/phoenix/access.log"], "success_condition": "[ $(cat /tmp/top_ips.txt | wc -l) -eq 5 ] && grep -q '192.168.1.1' /tmp/top_ips.txt"},
    {"prompt": [{"role": "system", "content": "The system logs in '/var/log/atlas' are consuming too much disk space. Compress all log files larger than 100KB into a single archive named 'large_logs.tar.gz' in the '/tmp' directory."}], "completion": [{"role": "assistant", "content": "# First, I need to identify all log files in '/var/log/atlas' that are larger than 100KB. Then, I will compress these files into a single archive named 'large_logs.tar.gz' in the '/tmp' directory."}, {"role": "user", "content": ""}, {"role": "assistant", "content": "find /var/log/atlas -type f -size +100k -exec tar -czvf /tmp/large_logs.tar.gz {} +"}, {"role": "user", "content": "/var/log/atlas/system.log\ntar: Removing leading `/' from member names\n"}, {"role": "assistant", "content": "exit 0"}], "id": "she_syn_t2012", "setup_commands": ["mkdir -p /var/log/atlas", "dd if=/dev/zero of=/var/log/atlas/system.log bs=1024 count=200", "dd if=/dev/zero of=/var/log/atlas/error.log bs=1024 count=50", "echo 'data' > /var/log/atlas/access.log"], "success_condition": "tar -tzf /tmp/large_logs.tar.gz | grep -q 'system.log' && ! tar -tzf /tmp/large_logs.tar.gz | grep -q 'access.log'"},
    {"prompt": [{"role": "system", "content": "The 'hermes-queue' service stores job files in '/var/lib/hermes/queue' with names like 'job_12345.data'. Find the largest file in the directory and save its name to '/tmp/largest_job.txt'."}], "completion": [{"role": "assistant", "content": "# To find the largest file in the directory '/var/lib/hermes/queue', I will use the 'ls' command with the '-lS' option to list files sorted by size (largest first). Then, I will extract the name of the largest file and save it to '/tmp/largest_job.txt'."}, {"role": "user", "content": ""}, {"role": "assistant", "content": "ls -lS /var/lib/hermes/queue | head -n 2 | tail -n 1 | awk '{print $9}' > /tmp/largest_job.txt"}, {"role": "user", "content": ""}, {"role": "assistant", "content": "exit 0"}], "id": "she_syn_t13724", "setup_commands": ["mkdir -p /var/lib/hermes/queue", "echo 'data1' > /var/lib/hermes/queue/job_12345.data", "echo 'data2' > /var/lib/hermes/queue/job_12346.data", "echo 'data3' > /var/lib/hermes/queue/job_12347.data", "du -b /var/lib/hermes/queue/job_12345.data > /dev/null"], "success_condition": "[ \"$(cat /tmp/largest_job.txt)\" = \"job_12345.data\" ]"},
    {"prompt": [{"role": "system", "content": "The 'atlas-analytics' service stores reports in '/data/atlas/reports', but some reports are outdated. Find all reports modified more than 30 days ago and move them to '/data/atlas/archive'."}], "completion": [{"role": "assistant", "content": "# To complete the task, I need to find all files in '/data/atlas/reports' that were modified more than 30 days ago and move them to '/data/atlas/archive'. The 'find' command can be used to locate these files, and 'mv' can move them. First, I'll verify the existence of the directories and then proceed with the command."}, {"role": "user", "content": ""}, {"role": "assistant", "content": "find /data/atlas/reports -type f -mtime +30 -exec mv {} /data/atlas/archive \\;"}, {"role": "user", "content": ""}, {"role": "assistant", "content": "exit 0"}], "id": "she_syn_t7195", "setup_commands": ["mkdir -p /data/atlas/reports", "mkdir -p /data/atlas/archive", "touch -d '35 days ago' /data/atlas/reports/report1.csv", "touch -d '40 days ago' /data/atlas/reports/report2.csv", "touch -d '20 days ago' /data/atlas/reports/report3.csv"], "success_condition": "find /data/atlas/reports -type f -mtime +30 | wc -l | grep -q '0' && find /data/atlas/archive -type f | wc -l | grep -q '2'"},
    {"prompt": [{"role": "system", "content": "The 'jupiter-monitoring' tool outputs system metrics to '/var/log/jupiter/metrics.log'. Calculate the average CPU usage percentage from the last 100 entries and save the result to '/tmp/avg_cpu.txt'."}], "completion": [{"role": "assistant", "content": "# To calculate the average CPU usage percentage from the last 100 entries in '/var/log/jupiter/metrics.log', we need to extract the CPU usage values, sum them up, and then divide by 100. The result should be saved to '/tmp/avg_cpu.txt'. The first step is to inspect the log file to understand its format and identify the CPU usage field."}, {"role": "user", "content": ""}, {"role": "assistant", "content": "head -n 1 /var/log/jupiter/metrics.log"}, {"role": "user", "content": "cpu_usage=25%\n"}, {"role": "assistant", "content": "# The log file format shows that each line contains a CPU usage value in the format 'cpu_usage=XX%'. To calculate the average of the last 100 entries, we need to extract these values, remove the '%' sign, convert them to numbers, sum them, and then divide by 100. The result should be saved to '/tmp/avg_cpu.txt'. The next step is to extract the last 100 CPU usage values from the log file."}, {"role": "user", "content": ""}, {"role": "assistant", "content": "tail -n 100 /var/log/jupiter/metrics.log | awk -F'=' '{print $2}' | sed 's/%//' > /tmp/cpu_values.txt"}, {"role": "user", "content": ""}, {"role": "assistant", "content": "# Now that we have extracted the last 100 CPU usage values into '/tmp/cpu_values.txt', the next step is to calculate the average of these values. We can use the 'awk' command to sum the values and then divide by 100 to get the average. The result will be saved to '/tmp/avg_cpu.txt'."}, {"role": "user", "content": ""}, {"role": "assistant", "content": "awk '{ sum += $1 } END { print sum / NR }' /tmp/cpu_values.txt > /tmp/avg_cpu.txt"}, {"role": "user", "content": ""}, {"role": "assistant", "content": "exit 0"}], "id": "she_syn_t556", "setup_commands": ["mkdir -p /var/log/jupiter", "for i in {1..100}; do echo \"cpu_usage=$((RANDOM % 100))%\" >> /var/log/jupiter/metrics.log; done"], "success_condition": "[ -f /tmp/avg_cpu.txt ] && grep -q '^[0-9]\\+%$' /tmp/avg_cpu.txt"},
]

def load_scenarios(
  split: Literal["train", "test"] = "train",
  limit: Optional[int] = None,
  shuffle: bool = False,
  seed: Optional[int] = None,
):
    if split == "test":
        dataset = Dataset.from_list(eval)
    else:
        dataset: Dataset = load_dataset(HF_REPO_ID, split=split)  # type: ignore

    if shuffle or (seed is not None):
        if seed is not None:
            dataset = dataset.shuffle(seed=seed)
        else:
            dataset = dataset.shuffle()

    # Convert each row (dict) in the dataset to a Scenario object
    scenarios = [
        Scenario(id=row['id'], task=row['prompt'][0]['content'], solution=row['completion'], # type: ignore
                setup_commands=row['setup_commands'],success_condition=row['success_condition'], split=split)  # type: ignore
        for row in dataset  # type: ignore
    ]

    if shuffle:
        if seed is not None:
            rng = random.Random(seed)
            rng.shuffle(scenarios)
        else:
            random.shuffle(scenarios)

    if limit is not None:
        return scenarios[:limit]
    else:
        return scenarios


if __name__ == "__main__":
    from rich import print

    scenarios = load_scenarios(limit=10, shuffle=True)
    print(scenarios)
